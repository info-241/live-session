# Problems and Diagnostics

```{r load packages for unit 11, echo = FALSE, message = FALSE}
library(data.table)
library(ggplot2)
```

```{r set colors for unit 11, echo = FALSE, message = FALSE}
blue <- "#003262"
gold <- "#FDB515"
```

![houston, we have a problem](./images/apollo_13.jpeg)

## Learning Objectives 

At the conclusion of this week's live session, students will be able to: 

1. **Recall** and enumerate the several types of problems that might arise in the process of conducting a *real-world* experiment. 
2. **Identify** and **diagnose** when these problems are present in *their* experiment. 
3. **Analyze** the consequences of these problems, and communicate to an audience how these problems affect the experiment's ability to produce an unbiased causal estimator.
4. **Propose** a way forward -- how to modify the experiment or modify the estimator. 

## Goals of an Expermient 

Recall that the goal of any experiment -- same as the goal for *your* experiment -- is to identify a causal effect that we have a **guarantee** is unbiased. If we cannot accomplish that, why take the time to conduct the experiment? 

Conducting these experiments is **easy**! At least in a perfect world. The reality is that this world that we live in, and that your data generating process functions within, is far from "perfect". And so, as a consequence, machines that we tell to record data fail; people that we tell to take treatment don't actually take it; doses that we think will be sufficient are not; and a litany of other small concerns! 

This week's task is to acknowledge that nothing will *ever* be perfect, and then to proactively design our data collection system so that we can diagnose problems when they arise. 

## Problems with Randomization 

Suppose that you are going to conduct an experiment that evaluates the effectiveness of encouragements to complete homework and you have designed the operational details in the following way: 

1. You have randomized the list of currently enrolled MIDS 241 students into three treatment groups. Group A will receive **Always Encouragement**, their instructor will Slack them every day and remind them that Problem Set 4 is coming due; Group B will receive **Baseline Encouragement**, where they will receive the normal communication from the class; Group C will receive **Conditional Encouragement**, where students will only be contacted if their grades are below the class average. 
2. Although you've designed the experiment, contact for students will require that the individual classroom instructors take action to send the encouragements. 

:::{.breakout}
1. **How could this randomization break?** In this breakout, list as many specific ways that you think that the list of people who are assigned to Group A, B, and C might not match those who actually are in the groups. How many ways can you imagine? 
2. **What are the consequences?** After listing all the ways that the randomization *could* breakdown, what are the three ways that you think would be more damaging to generating an unbiased causal estimate? 
3. **How would you detect?** For these three problems that you've identified, how would you know if the randomization has broken down in this particular way? 
:::

## Placebo Test 

Earlier in the semester, we talked about Placebo Designs, where we intentionally randomize a group of participants and give them a treatment that we do not think will affect outcomes. This placebo treatment, which you might think of as a sugar pill, is designed to allow compliers (and non-compliers) to identify themselves to the experimenting team, producing more efficient estimates of the compliers average causal effect when there is a lot of treatment non-compliance. 

This week, we introduce the concept of the *Placebo Test* which, importantly, is different than a *Placebo Design*. 

:::{.discussion-question}
What is a placebo test? How is the concept similar to, and how is it different from, a placebo design? 

- How do you know if a particular feature is a good candidate for a placebo test? 
- How are placebo tests different from covariate balance checks? 
- If you fail a placebo test, why is there more uncertainty about how to fix your experiment? 
:::

## Manipulation Check 

What happens if you don't use a *strong enough* treatment? 

:::{.example}
Suppose that you're conducting an experiment to learn the market-value effect of holding a MIDS degree from the School of Information. (Gosh, I sure hope it is positive!) You decide that your experiment is going to send two versions of a resume. 

1. **Version 1 (Control)**: The resume contains the candidate's name, work experience, skills, and a nice statement of their purpose searching for a job. But, the resume does not contain any information about a job candidates master's degree. 
2. **Version 2 (Treatment)**: The resume contains the candidate's name, work experience, skills, and a nice statement of their purpose searching for a job. Then, **after the other materials** the resume lists education at the top of the second page. 
::: 

:::{.discussion-question}
- What concerns do you have about the strength of this manipulation? How would you address these concerns? 
- What is the maximum manipulation that you can imagine using in this experiment? Are you concerned that there might be *too* much manipulation? 
:::

## Advocating for Experimentation 

Getting experiments done at work is *almost alwasys* an uphill battle! We won't enumerate the reasons (because we will ask you to do so in a moment), but in our experience, there are some serious impediemnts to getting experiments done. 

The good news, from the point of view of your company's leadership: [A/B Testing is Dead](https://venturebeat.com/automation/offerfit-gets-25m-to-kill-a-b-testing-for-marketing-with-machine-learning-personalization/). 

:::{.breakout}
Using the tools of this class and the program, in breakout rooms evaluate this claim. All breakout rooms will read and learn about this claim. 

One set will argue in support of the claim: Using new techniques like reinforcement learning and machine generated text, it is possible to determine the most effective messaging without needing to conduct randomized experiments. 

The other set of breakout rooms will argue against the claim: While these new techniques might afford some benefits, they cannot replace the work that we've been building over the course of the semester. 
:::

### Reasons for and against Experiments 

Think about getting an experiment conducted either at work or in your lab. 

:::{.discussion-question} 
- What are the reasons that you can identify *in support of* conducting an experiment? 
- What are the limitations to, or reasons that you might not conduct an experiment? 
::: 

