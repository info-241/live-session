# Apples to Apples

```{r load packages for unit 02, echo = FALSE, message = FALSE}
library(data.table)
library(ggplot2)
```

```{r set colors for unit 02, echo = FALSE, message = FALSE}
blue <- '#003262'
gold <- '#FDB515'
```

![fruit salad](./images/honeydew-salad-with-ginger-dressing-and-peanuts.jpeg)

## Learning Objectives 

At the conclusion of this week's live session, student will be able to:

1. *Describe*, using the technical language of potential outcomes, what it means for an input to *cause* an output. 
2. *Describe* the fundamental problem of causal inference. 
3. *Apply* iid sampling as a method of producing an unbiased, consistent estimator of a population. 
4. *Prove* that the average treatment effect estimator produces an unbiased, consistent estimator for the average treatment effect. 

## Revisiting Ideas of Science 

Questions about epistemology are a *classic* questions. These questions are particularly relevant here at the School of Information. You're working toward being a data scientist that has a full view of not only how to build the technology, but also for how that technology will behave, alter, and affect the people who use it.

The idea of epistemology -- the idea that some things are known truths, while others are merely opinions -- is perhaps one of the earliest philosophical (i.e. academic questions). 

> *What does it mean to **know** something?* 

"Do we know this is true, or do we just believe it to be true?" is more than just an academic question.  In our workplaces we need to know how to take the best course of action. As data scientists we need to know that the answers we are producing stand on some justification. And, for the purposes of this course, we are attempting to separate things that *certainly* cause an outcome from those that we *think* cause an outcome. 

### From last week

Think back to the reading and discussion from last week: For Feynman, what does it mean to be "Doing science?" 

- Would Feynman say that data science, as we are practicing it, is a "science"? 
- Would Feynman say that 205 is a science? 
- What about computer science or statistics? 

### From this week: Lakatos

For Lakatos, what does it mean for something to be a part of a science? What does it mean for something to be a part of a psuedo-science? Really, this is a question about how Lakatos draws a line between things that we *know* and things that we *believe*. 

- Is Lakatos' view as simple a view as Feynman espouses? 
- Where would Lakatos agree, and where would he disagree with Feynman on the "scientific" nature of the courses in the MIDS program? 

::: {.breakout} 
**What do you think produces knowledge?** 

Can a single conversation produce knowledge? Can a non-experimental study produce knowledge about a causal effect? 

Can an experiment fail to produce knowledge? If an experiment fails to reject some null hypothesis, does that mean that it has not produced any knowledge? 
::: 

## This Causes That

::: {.discussion-question}
**What does it mean "to cause"?**

In your own words, what does it mean for an action to *cause* an outcome? Do not focus on conducting an experiment to *measure* the cause; and don't worry about the difficulties of measurement. Just engage with the concept of what it means for something to cause. 

- How would you describe the idea of "cause" to a grandparent? See if you can describe it without relying on an example. Dig deeper to find the core essence of the concept? 
- How would you describe the idea of "cause" to a student who is enrolled in MIDS 203?
::: 

## Working Cases of Causality

In this short section, you are going to apply your breakout group's concept of causality against a series of scenarios. Rather than defining your concept using examples or scenarios, you have built a working conceptual definition that should be able to address the ideas of causality that they are confronted. If you find your group's working definition cannot address the scenario that it is faced with, take the time to alter the definition so that it *can* be useful. 

### Damn fine coffee

<iframe width="560" height="315" src="https://www.youtube.com/embed/Uvs7pmISe8I" title="Damn Fine Coffee" frameborder="0"></iframe>

Suppose that you're getting ready for class, and you want to make sure that you're at your best. So, you drink a cup of water, eat a small snack, and brew a small pot of coffee for while you're in class. 

> Why do you do this? 

Presumably, you're doing this because you like each of these things, but also because you're interested in these things causing you to have a better class. If you framed this as as causal question, you might ask: 

> If I drink a cup of coffee before class, will it cause me to be more alert? 

What does it mean for coffee to cause alertness? 

- Does coffee cause everyone to become more alert? 
- Does coffee have to affect everyone equally in order for you to say it causes alertness? 
- Could coffee have no effect for some people, and you would still say it causes alertness? 
  
### Meditation for focus 

Suppose that you're getting ready for class, and you want ensure that you're at your best. So, you find a quiet place, and set your mind at ease with whatever form of meditation you think might be helpful. 

> If I meditate before class, will it cause me to be more focused? 

What does it mean for meditation to cause focus? 

- Does meditation cause everyone to become more focused? 
- Does meditation have to affect everyone equally? 
- Some people are frustrated by not being able to quiet their thoughts, and actually find meditation frustrating. Can this be true, and still believe that meditation causes focus? 

### Selling coffee and meditation

Suppose that you're an enterprising soul, and you want to sell a book about brewing coffee as a meditation. You reason that there must be a niche for this approach. To get the word out, you place a few flyers with tear off phone-numbers at the local yoga studios and tech incubators (good intuition to find those MIDS students). 

> If shown a flyer for coffee-meditation, will it cause someone to take my training? 

What does it mean for for flyers to cause people to sign-up for the training?

- Does the flyer cause everyone to take the training? 
- Does the flyer affect everyone equally? 

One might be a radical behaviorist who believes that, "In matters of human behavior, if I cannot see it, then I cannot reason or know about."  If this is your view, then you would simply stop your investigation (and reasoning) at the conclusion of your experiment. 

In many ways, experiments suited only to answer empirical, observable questions. These are the questions, and lens proposed by the radical behaviorist paradigm. 

### Limits of Behaviorist Reasoning

Are you comfortable being a radical behaviorist? Are you willing to know only what you can see and observe and measure? 

Suppose that you run an experiment about whether coffee affects your alertness. And, you find that, "Yes! It does!" Then, as you're getting ready for class, and you want to be alert for the discussion, what might you do? 

Suppose that you go on a coffee-bender, and as you're getting ready for live session in week three, you go to the cupboard to brew a pot, and realize, "Oh no! I've drank all the coffee in the house! Now, I'll have to scramble to find something else to make sure that I'm alert in class." 

What would you go and consume to make you alert? Why do you think that this will be effective at making you more alert? Did you experiment tell you that this new substance would help make you more alert? 

If you're a radical behaviorist, or in this case, just a reasonable scientist do you have any knowledge of what you should drink? 

### Reflecting on Causes

Does anything unify questions of causes? 

When you think about *{this}* causing *{that}*, do you think about it at a population level, a smaller group level, or at the individual level? 

### Evaluating Value 

Is this an entirely academic exercise, the discussion of *{this}* causing *{that}*? Or, is there some value to thinking about things in these terms? Susan Athey, whom we read last week, seems to think that there is value in distinguishing between associations and causes. However, hers is a view that is generated by an academic; much like the views of David and David, and all of the live session instructors. We're all academics, so maybe we're being *typical* academic pedants. 

What is a case, perhaps that you read or wrote about for your first essay, mistakenly believing they had measured a causal effect? What would happen if they implemented the policy that is implicated in their study? Or, what would happen if they took action consonant with what their study purports to find? 

### Value of Theory

- Can you produce several theories (some of them might be silly) about why coffee might increase alertness in class? 
  - Proposed theory #1: 
  - Proposed theory #2:
  - Proposed theory #3:

- Does Feynman's approach to *Science* provide a method to adjudicate which of these theories is consonant with the evidence, and which are not consonant with the evidence? 
- Does Lakatos' approach to *Science* provide such a method? 

### Evaluating Theories 

- What data might you be able to produce that would allow you to "drive a wedge" between the different theories? 
- This ability to proactively deign an experiment to distinguish between theories is the goal you're striving to achieve, *and it is very hard to accomplish*. 

## Reading Discussion: The Power of Experiments 

*The Power of Experiments* starts the discussion of experimentation in the workplace with what is, for the course instructors, a uniquely pedestrian example, increasing contributions to taxes. In particular, Her Majesty's Revenue and Customs sends different versions of a letter to British taxpayers, and observes that different language leads to different amounts of taxes being paid. 

### Chapter One: The Power of Experiments

1. Is it *actually* a "big-deal" to increase tax compliance by 2 percentage points? 
2. On page five, the book identifies five "one-liners" that HMRC chose to send to taxpayers: 
  1. *Nine out of ten people pay their tax on time."* 
  2. *Nine out of ten people in the UK pay their tax on time.*
  3. *Nine out of ten people in the UK pay their tax on time. You are currently in the very small minority of people who have not paid us yet."*
  4. *Paying tax means we all gain from vital public services like the NHS, roads and schools.*
  5. *Not paying tax means we all lose out on vital public services like the NHS, roads, and schools.* 
3. Which of these sentences would be the most effective at getting you to pay your taxes? Which do you think will be most effective, overall, at generating tax compliance? Why? How willing are you to make a million pound bet that you're correct? 
4. Some of your instructors are vegetarians. None of them, however, has previously made an argument for why everyone should be vegetarian based on the example of Daniel and his study of diet and divine intervention. What about the study that Daniel conducted produces evidence that you think is useful for evaluating diet? What are the limitations that you see in this study? The book lists several, but there are other issues, along the lines of  the *exclusion restriction* that *Field Experiments* identifies. 
5. In order for Pasteur to be declared the winner of the vaccine argument, the observers said that every control group sheep had to die and every treatment group (i.e. vaccine-receiving) sheep had to live. Is this a fair burden of proof? Do the frequentest tests that we developed in 203 and are going to use here in 241 set a higher or lower bar than Pasteur faced? What are the merits of a relatively higher or lower bar? 

### Chapter Two: The Rise of Experimetnts in Psychology and Economics

Freud is noted as being specifically *against* experimentation. But, *PoE* then goes on to write, "[Freud's] big ideas inspired entire fields of psychological research. Including the notion that unconscious processes shape our judgement and behavior, psychological disorders are rooted in the mind rather than the body; and that sexual urges and behavior are worthy of study" (p. 19). Some of the theories that Freud promulgated were found to have evidence that was consistent with the theory; some of these theories could not produce evidence to support the theory; and many were outright contradicted by the evidence.

1. Is there value in being an "idea person"? How would you ever know if your ideas were actually right if you're unwilling to evaluate them? 
2. What, if any, are the limitations of experimenting without any "big ideas" to ground your experiments? 

Behaviorists (Skinner is the leading behaviorist) make a compelling argument: "One cannot directly observe what is happening in the mind of a person." A classic implication of this argument for behaviorists is that only that which is empirically observable is reasoned about. "Why does the rat avoid getting shocked? Does it really matter?" "Why does the child want a cookie? Does it really matter why?" 

1. Is this position reasonable for you to take as you navigate your own life? If you spoke with a therapist or a coach and said, "I've been feeling stressed over the past several weeks," would be satisfied with a *mindful* answer like, "Well, let's acknowledge those feelings and hold them for a moment" or would you want to reason further about why you feel stressed? What are the types of things in people's heads that you think we can profitably reason about; what are the types of things in people's heads that we cannot reason about? Is there something that is common to those that we can or cannot work with? 

The experiments of Milgram and Zimbardo are widely identified as the reason that human-subjects review boards no exist. These review boards serve as an external review that keeps researchers from inflicting harm to individuals that is not outweighed by societal or scientific benefits. 

1. What did Milgram and Zimbardo do to their subjects?
2. By talking continuing to talk about these experiments nearly fifty years after they were conducted -- even if we are talking about them negatively -- are we adding to the fame of these researchers? (For those interested in inside baseball, Zimbardo was the president of the American Psychology Association in 2002, and was awarded a lifetime achievement award from his discipline.) How should we learn and react to work that shouldn't have been conducted in the first place? 

Kahneman and Tversky propose that individuals think about expected values differently depending on whether they are thinking in the domain of gains or the domain of losses. They come to this theory through the, now cringe-worthy, *Asian Disease Problem*: 

In the positive frame, they ask the question: 

> Imagine that the US is preparing for the outbreak of an unusual Asian disease that is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. 
> 
> - If **Program A** is adopted, 200 people will be saved. 
> - If **Program B** is adopted, with a 1/3 probability 600 will be saved and with a 2/3 probability nobody will be saved.
> 

The authors also present a countervailing pair of scenarios framed in terms of losses

> - If **Program C** is adopted, 400 people will die. 
> - If **Program D** is adopted, there is a one-third probability that no one will die, and a 2/3 probability that everyone will die. 

Clearly, all these programs have the same expected number of deaths; but, people can disagree about which of these is the program that we should pursue. Just ask as a poll in the class; and, ask people to justify their beliefs. 

### The Rise of Behavioral Experiments in Policymaking 

*PoE* points out that experiments abound in policy making. Part of this stems from a truthful ignorance of the optimal policy to pursue. Another part of this stems from the ability of policy makers to make decisions by fiat that affect a large number of people. 

1. Does this justification for experiments align with your current understeanding of the landscape in human-facing data science? 

In a section titled **The nuance behind behavioral insights** the authors state a series of three caveats: 

> 1. *Context matters*
> 2. *Design choices matter* 
> 3. *Unintended consequences abound* 

1. What do they mean when they raise the three points?
2. We are going to ask you to justify conducting experiments by staking out an extreme point of view, and asking you to convince us that this point of view is so extreme that it cannot be justified. *"Writing that context matters, design choices matter, and unanticipated consequences abound is little more than writing that experiments cannot produce any more useful insights than the theories of Freud. As a result, there is little reason to conduct any experiments because what we learn will be highly contextualized, affected by very small implementation choices, and may generate as many (or more) negative outcomes as positive outcomes."* 

## Potential Outcomes

Potential outcomes are a system of reasoning, and a corresponding notation, that allow us to talk about observable and un-observable characteristics of the world. 

> What is your position on *ontology*? What does it mean for something to exist? 

- Does *Field Experiments*, as a textbook, exist? 
- Do Don Green and Alan Gerber, the authors of the textbook that we're reading, exist? 
- Does David Reiley, the slower-talking Davids in the async, exist? 
- Do I, your section, instructor, exist (or am I a deep fake in this room with you)?
- Can a concept exist, even if you can't hold it? Even if you haven't seen it? 

### Defining Potential Outcomes 

For each of the following sets of notation: (1) Read the notation aloud, not as "Y sub i zero", but instead as "The potential outcome to control ...". 

- $Y_{i}(0)$: 
- $Y_{i}(1)$:  
- $E[Y_{i}(0)]$: 
- $E[Y_{i}(1)]$: 
- $E[Y_{i}(0)|D_{i}=0]$:
- $E[Y_{i}(1)|D_{i}=1]$:
- $E[Y_{i}(0)|D_{i}=1]$:
- $E[Y_{i}(1)|D_{i}=0]$:

- Which of these concepts that you have just read aloud exist? 
- Can a concept exist, even if you can't hold it? Even if you can't see it? 

## Using Independence 

Suppose that you have a random variable that is defined as the function, 

$$
Y = 
  \begin{cases}
    \frac{1}{10} & ,0 \leq y \leq 10 \\ 
    0 & \text{, otherwise}
  \end{cases}
$$

- What is the expected value of this function? 

$$
\begin{aligned}
  E[Y]  &= \int_{0}^{10} y \cdot f_{y}(y) \ dy                       \\ 
        &= \int_{0}^{10} y \cdot \frac{1}{10} \ dy                   \\ 
        &= \frac{1}{10}\int_{0}^{10} y \ dy                          \\ 
        &= \left.\frac{1}{10} \cdot \frac{1}{2}  y^2\right|_{0}^{10} \\ 
        &= \left.\frac{1}{20}  y^{2} \right|_{0}^{10}                \\ 
        &= \frac{1}{20} \cdot \left[(100) - (0) \right]              \\ 
        &= \frac{1}{20} \cdot 100                                    \\
        &= \mathbf{5}
\end{aligned}
$$

- Why is the expected value a good characterization of a random variable?

- If you wanted to write down an estimator to produce a summary statistic for $Y$ given a sample of data, what properties do the following estimators possess: 

- $\hat{\theta}_{1} = y_{1}$
- $\hat{\theta}_{2} = \frac{1}{2} \displaystyle\sum_{i=1}^{2} y_{i}$
- $\hat{\theta}_{3} = \frac{1}{n-1} \displaystyle\sum_{i=1}^{N} y_{i}$
- $\hat{\theta}_{4} = \frac{1}{n} \displaystyle\sum_{i=1}^{N} y_{i}$

```{r make population function} 
conduct_sample <- function(size) { 
  runif(n=size, min=0, max=10)
}
```

```{r write estimators}
theta_1 <- function(data) { 
  # take the first element
  
}

theta_2 <- function(data) { 
  # sum the first two elements and divide by two
  
}

theta_3 <- function(data) { 
  # sum the sample, and divide by 1 less than the sample size
  
}

theta_4 <- function(data) { 
  # sum the sample, and divide by the sample size 
  # honestly, just use the mean call. 
  # clearly, this is a silly function to write, since you're just 
  # providing an alias, without modification, to an existing function. 
  
  mean(data)
  
}
```

```{r use estimator 04}
theta_4(conduct_sample(size=100))
```

- Just to put a fine point on it: **What estimator properties does the sample average provide, and why are these desirable?" 

## Use Randomization to Produce Independence 

How can we use the independence that is induced by "random **assignment** to treatment" combined with the sample average estimator to produce an estimate of an otherwise very difficult concept to measure? 

## Theoretical Justification

Before we show that this very simple ATE estimator work against a sample of data, it is worth reasoning about whether we can guarantee that it works in a general case. If we can show that it works in a general case, then any specific case inherits that guarantee. However, if we can only reason thorugh the existence of a single examlpe, it is not a sufficient argument to compell us to believe that it must hold for all cases. 

Here's an example, "Behold! I see a black sheep! Therefore all sheep are black." This doesn't make sense, and it is not a logically sound argument. However, if you say, "All sheep say, 'Baaah!' This is a black sheep, so it must say 'Baah!'" is a logically sound arugment, so long as the antecedent is, in fact true. When we're proving something, we're proving that the antecedent to this statement is generally true. For anyone who took a symbolic logic course in, this method of argument might be marked down as $\forall X \implies \exists X$, whereas $\exists Y \not\Rightarrow \forall Y$. 

- What concepts compose $\tau_{David}$? 
- What concepts compose $\tau_{i}$? 
- Is there any reason to believe that $\tau_{David\ Reiley} = \tau_{David\ Broockman}$? 
- Is there any reason to believe that $\tau_{i} = \tau_{j}$, where $j \neq i$? 
- Could $\tau_{i} = \tau{j}$?
- What is the fundamental problem of causal inference?

The proof for this argument is also made in *Field Experiments*, on or about page 30 of the text. However, in our view, the authors don't give enough room to fully develop this proof, and so we skipped right past it the first time that we read the chapter. 

Begin our proof with the statement for what a treatment effect is, $\tau_{i}$. 

$$
  \begin{aligned} 
    \tau_{i}    &= Y_{i}(1) - Y_{i}(0)    & Definition   \\ 
    ATE         &= E[\tau]                & Definition   \\
                &= E[Y(1) - Y(0)]         & Substitution \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
                &=                                       \\
  \end{aligned}
$$

## Simulation Example

Now, let's work through an example that shows this works not only in the math, but also in the realized, i.e. sampled, world. 

To begin with, lets work with a *very* simple sample that has 100 observations, potential outcomes to control are uniformly distributed between `0` and `1` and every single unit has a potential outcome to treatment that is `0.25` units larger than their potential outcomes to control.  

```{r create data}
make_simple_data <- function(size=100) { 
  require(data.table) 
  
  d <- data.table(id = 1:100)  
  
  d[ , y0 := runif(.N, min = 0, max = 1)]
  d[ , y1 := y0 + .25]
  
  return(d)
  }

d <- make_simple_data(size=100)

d[1:5]
```

In this world, we've taken a sample of `100` individuals, and at this point, each of those individuals that we've sampled has both a potential outcome to control **and also** a potential outcome to treatment. We haven't talked at all about measurement yet; we're just asserting that both of these potential outcomes exist for each person. 

Essentially, this stage of creating the sample is the same as bringing people in the door to your experiment. If you were running this in the laboratory, you'd literally think of this as sitting your subjects down at their chairs, getting ready to begin their task. 

> Is randomly sampling people to be a part of your experiment sufficient to ensure that your experiment produces an unbiaed, consistent estimate of the true treamtent effect? 

Suppose that for each unit, you then toss a coin, placing the subject either into treatment or control based on the result of that coin flip. 

- Does this coin flip ensure that you have the same number of units in treatment as control? Does this matter to you? Why or why not? 
- Are there other ways that you could assign individuals to treatment an control, rather than through a simple-randomization process? 
- What are the relative merits or limitations of each of the methods?
- Are some of these methods *more random* than others? Or, are all things that are random equal in their randomness? 

### Assign to Treatment and Control
```{r assign units to treatment and control at random}
d[ , experimental_assignment := sample(0:1, size = .N, replace = TRUE)]
d[1:5]
```

As as comparison, suppose that instead of randomly assigning individuals into treatment and control we allowed individuals to select into treatment and control. And suppose that people with the lowest potential outcomes to control opt to take the treatment. You might think of this as being something like, "The people who are the most tired are the most likely to drink a cup of coffee before they start class," if an example helps you ground this. 

Specifically, suppose that any unit that has a potential outcome lower that `0.33` opts to take the treatment. 

```{r allow observational selection into treatment}
d[ , observational_selection := ifelse(y0 < .33, 1, 0)]
d[1:5]
```

These represent two different ways that you might conduct your research, each time with the same subject pool. Of course, in reality you probably would not be able to run these two studies at the same time, but since this is a simulation, we can stretch the confines of reality just a little bit. 

```{r create first plot}
first_plot <- ggplot(data=d) + 
  geom_point(aes(x = id, y = y0), color = blue) + 
  geom_point(aes(x = id, y = y1), color = gold)
first_plot  
```

What's actually happening in this? It might be more clear if we add arrows to this plot to show. 

```{r show the movement between potential outcomes}
first_plot +
  geom_segment(
    aes(x = id, xend = id, y = y0, yend = y1), 
    arrow = arrow(ends = 'last', length = unit(0.1, "inches"), type = 'closed'), 
    color = 'grey70'
    )
```

Even though these potential outcomes exist for all the units, is it possible to actually see them for all the units? How do we go about showing, and then measuring the potential outcomes to control for a set of units? How about the potential outcomes to treatment? 

```{r add points to plot}
second_plot <- ggplot(data = d) + 
  geom_point(
    aes(x = id, y = y0, size = 1 - experimental_assignment), 
    color = blue) + 
  geom_point(
    aes(x = id, y = y1, size = 0 + experimental_assignment), 
    color = gold) + 
  labs(
    title = 'Treatment and Control Assignment', 
    size = 'Treatment or Control'
  )

second_plot
```

What are the averages of these samples that have been assigned to treatment? 

```{r add estimates from unbiased estimator}
third_plot <- second_plot + 
  geom_hline(
    yintercept = mean(d[experimental_assignment==0, y0]), 
    color = blue, 
    linetype = 2) + 
  geom_hline(
    yintercept = mean(d[experimental_assignment==1, y1]), 
    color = gold, 
    linetype = 2)
third_plot
```

Even though we aren't able to see it, can we reason about what the sample average would be if we could see both of an individual's potential outcome to treatment and control? 

- Is there a guarantee that the sample should be the same as the feasible realization? 
- Should they be close? What property from 203 provides this guarantee? 

```{r add population expected values}
third_plot + 
  geom_hline(yintercept = mean(d[, y0]), color = blue, linetype = 1) + 
  geom_hline(yintercept = mean(d[, y1]), color = gold, linetype = 1)
  
```

Put it all together, what has this little demo shown? 

### What if there is selection?

What if, rather than being assigned to treatment and control, instead individuals had been able to opt into treatment and control? 

Produce only the last plot, but this time for the observational, or selected data. 

```{r recreate plot -- for selection case}
selection_plot <- ggplot(d) + 
  geom_point(
    aes(x = id, y = y0, size = 1 - observational_selection), 
    color = blue) + 
  geom_point(
    aes(x = id, y = y1, size = 0 + observational_selection), color = gold) + 
  geom_hline(
    yintercept = mean(d[, y0]), 
    color = blue, 
    linetype = 1) + 
  geom_hline(
    yintercept = d[observational_selection == 0, mean(y0)], 
    color = blue, 
    linetype = 2) + 
  geom_hline(
    yintercept = mean(d[, y1]), 
    color = gold, 
    linetype = 1) +
  geom_hline(
    yintercept = d[observational_selection == 1, mean(y1)], 
    color = gold, 
    linetype = 2) + 
  labs(
    title = 'Observational Selection into Treatment', 
    size = 'Treatment or Control'
  )

selection_plot
```

## Requirements of An Experiment 

David Reiley makes the case that an experiment is something where we intervene in the world to produce knowledge. This is essentially providing a definition and making an argument that this is the correct definition. One difficulty with argument through definitions is that reasonable people can disagree because their definitions, through their lived experience, just disagree. 

Here's the demonstrated proof: 

> Who in class is from the "midwest" broadly defined? Is Chicago-style pizza, pizza *per se*? 
> Who in class is from the east coast? Is Chicago-style pizza, pizza *per se*? 
> 
> Try not to make deep character judgments about your classmates. 

Green and Gerber, in *Field Experiments* make additional requirements of experiments. As they argue on page 45 of the textbook, in their view, experiments require: 

1. **Random Assignment** 
2. **Excludability** 
3. **Non-interference** 

What do each of these terms mean? Why is each necessary? 

- Did the experiment that Daniel conducted, described in *Power of Experiments* satisfy these three requirements? For any of these requirements that David's experiment did not satisfy, what are the consequences for the scientific knowledge that the experiment generated?  
- Did the Nurses Health Study, described in the async, satisfy all these three requirements? For any that this experiment did not satisfy, what are the consequences for the scientific knowledge that the experiment generated? 

### Meta-Questions

- Can an experiment generate scientific knowledge about a causal effect, even without satisfying all of these requirements? Is it guaranteed to produce scientific knowledge about a causal effect? 
- What then, justifies the use of experiments to measure causal effects?