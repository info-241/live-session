```{r}
library(data.table)
library(ggplot2)
library(here)
```


# Heterogeneous Treatment Effects

When we consider heterogeneous treatment effects, we acknowledge that it is very unlikely that every single person reacts to treatment in exactly the same way. But, are there certain *types* of people who always react more strongly to treatment? Are there certain *types* of people who always react less strongly? 

How should we go about (a) looking for HTEs; (b) testings for HTEs with nominal p-value coverages; and (c) reporting HTEs to individuals in a way that make sense? 

## Learning Objectives 

At the end of this week, students will be able to 

1. Understand what an HTE is, and what it is not. 
2. Conduct, test, and interpret models with interaction terms as specific tests of hypotheses. 

## Reading and Discussion: Goodson

1. Why do we call them A/B tests, rather than experiments? Are you uncomfortable with the idea that companies are experimenting on you? Are you uncomfortable experimenting in your subjects? If there is a gap between your feeling about being experimented **on** compared to how you feel when you are **doing** the experimenting, why does this gap exist? 
2. What is an A/B test in Goodson's estimation? 
3. How should we know when a test should be determined to be complete? How should we determine that one experience is *causing* different behaviors in our reference population than another experience? 
  - Can we decide this while we are working through the experiment? 
  - Can we make this choice when we see the outcome that we thought we were going to see? 
  - Can we be *sure* that we have set the correct stopping rules ahead of time? 
4. What are the consequences of peaking, and then stopping early, once we have seen the results? 

## Coding and Demo: The Californians 

```{r data simulation function, eval = TRUE, echo = TRUE}
library(data.table)
library(stargazer)

make_data <- function(sim_size) { 
    d <- data.table(
      id              = 1:sim_size,
      cal_stanford    = rep(c('cal', 'stanford'), each = sim_size/2),
      affluence       = c(
        sample(1:7, size = sim_size/2, replace = T, prob = c(.1, .2, .2, .2, .2, .05, .05)),
        sample(1:7, size = sim_size/2, replace = T, prob = c(.05, .05, .05, .15, .2, .2, .3))),       
      founder_motivation = rnorm(sim_size, mean = 100, sd = 7), 
      treatment_group = sample(c(0,1), sim_size, replace = TRUE)
      )

    d[ , capital_access := rnorm(sim_size, mean = d$affluence, sd = 2)]
    d[ , tau            := rnorm(sim_size, mean = 5 + 5*I(cal_stanford == 'cal') + affluence)]
    d[ , founding_prob  :=  founder_motivation + tau*treatment_group]
    
    return(d)
}
```

```{r create data for sim}
d <- make_data(sim_size = 1000)
```

### Overall Treatment Effect 

What is the (unobserved) true average treatment effect? Estimate a model that includes only the treatment effect and interpret all the coefficients.

```{r baseline model}
model_0 <- d[ , lm(founding_prob ~ treatment_group)]
```

### Founder Motivation 

Estimate a model that includes the (nearly impossible to measure) variable about `motivation`. What happens to your estimates? Why does this happen? 

```{r motivation model}
model_1 <- d[ , lm(founding_prob ~ treatment_group + founder_motivation)]
```

Print these two modeles next to one another and describe what is happening and why.

- Are the intercept terms the same? Why or why not? 
- Are the standard errors teh same? Why or why not? 
- Are the estimate treatment effects the same? Why or why not? 

### Subset Models 

Subset the data into two groups based on `cal_stanford` and estimate
a model that only includes the treatment effects.

Print these two models side by side, and tell me what is going
on.

```{r}
model_cal      <- d[cal_stanford == 'cal', lm(founding_prob ~ treatment_group)]
model_stanford <- d[cal_stanford == 'stanford', lm(founding_prob ~ treatment_group)]

stargazer(
  model_cal, model_stanford, 
  type = 'text'
)
```


Based on this, would you conclude that these are different? Use the `confint()` function on each of these models to inform this discussion -- this is a total trap, because there is very weak statistical basis for what you're about to say, but do it anyways. 

### Interaction Model To Test 

The models that you estimated above are extremely intuitive to talk about, and are probably the right models to report to collaborators, especially those who aren't read into this class. **But**, they don't include a formal statisical test. 

To conduct this test, we're going to rely on the **same model form** as we used for treatment-by-treatment investigations -- the difference in differences model. 

Estimate a model that interacts the treatment indicator with the `cal_stanford` indicator, and report what you see from this model. 

```{r}
model_interaction <- d[ , lm(founding_prob ~ treatment_group * cal_stanford)]

summary(model_interaction)
```


## ? anova

## Finally, use the results from model 5 to tell me what the treatment
## effect is for males and for californians.


## 
## AT HOME:
## Work to examine what including the other affluence and literacy
## triggers does to your estimates.
##

## Coding and Discussion: Tips at a Restaurant 

```{r, eval = FALSE, echo = TRUE}

## Green and Gerber: Question 9.6
## a, b, and c. 

d <- fread('http://hdl.handle.net/10079/cd6be01a-a827-4312-a2fa-74329ce7f96d')

## a. (Probably skip this one)
##    Suppose that you ignored the gender of the server and simply analyzed whether
##    the happyface treatment has and effect (and/or) a heterogeneous effects. Use randomization inference 
##    to test whether the Variance of \tau = 0 using randomization inference by 
##    comparing the variance of potential outcomes in treatment and control. 

## b. Write down a regression model that depicts the effect of the gender of 
##    the waitstaff, whether they put a happyface on the bill, and the interaction 
##    of these factors. 
## 

## c. Estimate the regression model that you wrote down in (b) and test the 
##    interaction between waitstaff and the happyface treatment. 
##    Is the interaction significant. 

## d. Waiting tables in the time of covid: Suppose that you're on the waitstaff 
##    at this restaurant, and while you're waiting tables you're FULLY garbed 
##    up: facemask, face-shield, full operating gown, and so on. 
##    What this means is that you have the choice to reveal a gender identity
##    that is either "Male" or "Female" to the patrons. 
## 
##    - Is there one gender identity that receives higher tips in this restaurant? 
##    - Is there a gender that has a higher treatment effect? What is the 
##      test that you would run to assess this? 
```

## Sleeeeeeeeeeeep...

Suppose that you've conducted an experiment to evaluate the effectiveness of meditation prior to sleeping. Some people are free to do what they want, while others are assigned to a 10 minute guided mindfulness exercise before they go to bed. Treatment is randomly assigned at the individual-level, and people are placed into their groups (and maintained in those groups) for 10 days; then, after two weeks, the groups are flipped. 

1. What does the design of this experiment look like? 

    R
    R

2. Suppose that you also possess some data about the individuals. Specifically, you collect: 
  1. Their age; 
  2. Their coffee drinking habits; 
  3. Their tea drinking habits; 
  4. The number of people in their bed on a typical weeknight; 
  5. The number of cats they own; 
  6. The number of dogs they own. 

3. First, is there an effect of treatment? Combine the data that you have on hand to write the first, best model. 
4. Are there are parts of the population that this is especially effective (or ineffective)? How do you know? 

```{r}
load(file = here("data", "sleep_study.Rdata"))
```

```{r}

```

