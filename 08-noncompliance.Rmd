# Treatment Noncompliance

```{r load packages for unit 08, echo=FALSE, message=FALSE, warning=FALSE}
library(data.table)
library(magrittr) 

library(AER)
```


This begins a section of the class where we are going to evaluate what happens when problems creep into the actual experiments that we are conducting. We are first going to look at what happens when we instruct people to take treatment, but they choose not to. Or, when we instruct people to take control, but they choose to take treatment instead.

It might seem, at first, like we should just proceed by analyzing according to the treatment condition that they actually received. However, because we haven't experimentally assigned this condition, this creates an unprincipled estimator.

This doesn't mean that all is lost however. We can redefine the causal quantity that we are estimating, and produce a reliable estimate of this new concept.We're going to present two such concepts this week. The first concept is the idea of the intent to treat effect (the ITT). The second concept is the idea of the treatment effect among compliers, which we will call the CACE.

## Learning Objectives 

1. **Recognize** when experimental units have not complied with the treatment assignments they were given, and **appreciate** that this causes problems for our two-group estimator.
2. **Recover** causal estimators, but for sub-populations of the overall population. 
3. **Utilize** a new class of model, the two-stage least squares model, or 2SLS, which is the appropriate model choice when we are dealing with either one- or two-sided non-compliance. 

## Starting conversation 

Life on campus is exciting! Whether students are involved in affinity groups, advocacy groups, protest groups, or just party groups, student life on campus is exciting. We're not to be left out! We're not to be denied the chance to make our voices heard. 

But, because we're usually calling in via Zoom, we don't have the typical problems that students and faculty complain about -- parking, enrollment, sports tickets, and beer availability. What we do have to complain about is that "*god awful*" sound of the bell-tower ringing every hour on the hour. 

Suppose that we are to discuss this *very.* *important.* *issue.* before a panel of the deans and University administration. And, further suppose that in light of global events of the past several years, they're actually amenable to what we're proposing -- cutting off those bells, and providing the Berkeley Carillon player a generous retirement. 

![University Carillonist](https://www.youtube.com/watch?v=K_8vta9XDpc)

However, there's a catch. They are worried that taking such an action would be detrimental to the student experience on campus, and they would like to measure the causal effect of playing vs. not playing the Carillon while students are changing classes. 

In breakout rooms, please design an experiment that would be able to measure the difference in student experience. You will have to propose a measurement, a timescale for that measurement, and a feasible randomization that *could actually* occur given the real-world constraints that what is at question are loud sounds emanating from a 300 foot tower in the middle of a large, busy campus. 

If there are any limitations to what you design, please voice those concerns and talk about why they arise, relative to an *ideal* experiment (that you are probably unable to conduct). 
    
## Non-compliance Discussion

- What is ITT? 
- What is ITT_{d}? 
- What is the CACE? 
- How does this produce an apples to oranges comparison? 
- What is the exclusion restriction, and why is it important in this case? 

## Estimating with Non-compliance 

### Estimating with non-compliance 

```{r make data for non-compliance}
## install.packages("AER")      # this has a nice wrapper for iv regression
                                # but we can do it by hand with VERY little work 

nrows = 1000
d <- data.table(id = 1:nrows) 

d[ , y0 := rnorm(nrows, mean = 10)]
d[ , tau := rnorm(nrows, mean = 5)]
d[ , y1 := y0 + tau]

d[ , assigned := sample(rep(c(0,1), each = nrows / 2))] # z in the book
d[ , treated := 0] 
d[assigned == 1, treated := sample(c(1,0), size = .N, replace = TRUE, prob = c(.7, .3))]

d[treated == 1, Y := y1]
d[treated == 0, Y := y0]
```

```{r confirm tau}
d[ , mean(y1 - y0)]
```

But, that has all the data in the science table. In real life, we won't get this. 

```{r}
d2 <- d[ , .(assigned, treated, Y)]
d2[ , .(mean = mean(Y)), by = assigned][ , diff(mean)]

5 * .7
## rats. we /know/ that the treatment effect is 5, but when we look at the
## intent to treat effect, we only estimate a difference of 3.5 or so. 

```


Suppose that we cannot evaluate whether someone was /actually/ treated or not. 
  - In this case, we will ONLY be able to recover the ITT. 
  - This requires that you suspect reality for a moment and suppose we don't have the `treated` measurement. 
  
### Estimate the Intent to Treat Effect

```{r estimate the itt}

```

### Estimate the Compliance Rate 

```{r estimate the compliance rate}

```

### Compute the CACE 

Because you have the ITT and the compliance rate, estimate the CACE

```{r compute cace}

```

### Do you get the same thing with this subset estimator? 

```{r cace thorugh subsets?}
d2[assigned == 1 , .(group_mean = mean(Y)), by = .(treated)] %>%
    .[ , diff(group_mean)]
```

Notice that this does not have  clear estimate of the uncertainty associated with it. This is a bummer.  

In order to estimate with a reliable standard error, we can turn to two stage least squares.

## Two Stage Least Squares

Two-stage least squares estimators have the benefits of

1. Doing _exactly_ the same thing that the CACE = ITT / ITT_{d}; but,
2. Doing it in a way that has known standard errors that are quickly and easily computable. 

### First Stage 

In the first stage we: 

- Estimate the proportion of people who are receive treatment as a function of being assigned to treatment. 
- In the case of one-sided non compliance this is _exactly_ the same thing as estimating the
   ITT_{d}, right?
   
```{r 2sls first stage}
first <- 'fill this in'
```
   
```{r the make predictions}
## calculate the fitted values from this regression
##   - that is, just multiply the coefficients that you estimate from the
##     first stage times the data values. In the event that the exclusion
##     restriction holds, then these predictions are just orthagonal to every
##     thing that is not modeled in your data! 

```


d2[ , predict := predict(first)]

### Second stage 

In the scond stage we: 

- Estimate the relationship between the predicted values and the outcome. 
- This will just tell you how the outcome changes in response to the amount of change that your treatment assignment is able to produce.


```{r 2sls second stage}
second <- 'fill this in'
# coeftest(second, vcovHC(second, type = "const")) ## these ses might be wrong. 
```


```{r AER}
## I'll note that the standard errors from this "hand-rolled" 2SLS will not
## be correct (due to some accounting issues in the variance between the predictions
## in the first stage and the second stage.
##
## we can fix this by hand -- though I wouldn't -- or we can use a library that will
## do the accounting for us, from the library AER

library(AER)
iv.model <- ivreg(Y ~ treated | assigned, data = d2)

coeftest(iv.model, vcov = vcovHC(iv.model, type = "const"))

```